{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Phân tích dữ liệu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVv2t2FWeRan"
      },
      "source": [
        "# Phân tích dữ liệu là một yếu tố rất quan trọng để xây dựng một mô hình tốt\n",
        "![Image](https://rochemamabolo.files.wordpress.com/2014/11/garbage-in-garbage-out.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCLc4lISHJAE"
      },
      "source": [
        "# Install venv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elTRZD32HLfA"
      },
      "source": [
        "!pip install cython pyyaml==5.1\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFvbyf5iHbBA",
        "outputId": "190ac30b-97cf-4d5b-d8dc-41245d99faaf"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9604 (delta 0), reused 1 (delta 0), pack-reused 9597\u001b[K\n",
            "Receiving objects: 100% (9604/9604), 3.83 MiB | 2.88 MiB/s, done.\n",
            "Resolving deltas: 100% (7055/7055), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9pbLwz3PQrb"
      },
      "source": [
        "# Tải dữ liệu sử dụng gdown "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvlziHUuO3Ak",
        "outputId": "ed75540c-85ea-4d05-8c76-e46b3a94ebbc"
      },
      "source": [
        "!gdown --id 1BlZ8t-SgcHh26wrNXau76Yg0Aq5Fd9V4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BlZ8t-SgcHh26wrNXau76Yg0Aq5Fd9V4\n",
            "To: /content/TRAIN.zip\n",
            "469MB [00:04, 102MB/s] "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m7Ibi45QcM8"
      },
      "source": [
        "!unzip TRAIN.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt6IwG_6PV2u"
      },
      "source": [
        "# Khai báo thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC5g2Nk8PX6Y"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.patches as patches\n",
        "import seaborn as sns\n",
        "import glob2\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import imutils\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.io import output_notebook, show, output_file\n",
        "from bokeh.models import ColumnDataSource, HoverTool, Panel\n",
        "from bokeh.models.widgets import Tabs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSD00MNfSDgL"
      },
      "source": [
        "# Lấy bounding box và vẽ ảnh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOmnRo-pR-xX"
      },
      "source": [
        "def get_all_bboxes(annot_path):\n",
        "    list_info = []\n",
        "    with open(annot_path) as f:\n",
        "      content = f.readlines()\n",
        "    \n",
        "    content = [x.strip() for x in content] \n",
        "    for line in content:\n",
        "      line = line.split()\n",
        "      class_id = int(line[0])\n",
        "      bbox = [int(line[1]), int(line[2]), int(line[3]), int(line[4])]\n",
        "      info_box = [class_id, bbox]\n",
        "      list_info.append(info_box)\n",
        "  \n",
        "    return list_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_Ds02GITZbm",
        "outputId": "65daae00-03c9-44c3-e70d-69dc959cea3d"
      },
      "source": [
        "list_info = get_all_bboxes(\"TRAIN/TRAIN_0.txt\")\n",
        "list_info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, [989, 66, 1029, 101]],\n",
              " [1, [949, 67, 983, 100]],\n",
              " [1, [528, 342, 541, 356]],\n",
              " [1, [876, 387, 893, 400]],\n",
              " [3, [1033, 69, 1067, 103]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYZrgzFYTksa"
      },
      "source": [
        "def draw_image(image_name):\n",
        "  image = cv2.imread(image_name)\n",
        "  annot_path = os.path.join(\"TRAIN\", (image_name.split(\"/\")[1]).split(\".\")[0] + '.txt')\n",
        "  \n",
        "  list_info = get_all_bboxes(annot_path)\n",
        "  for info in list_info:\n",
        "    class_id = info[0]\n",
        "    bbox = info[1]\n",
        "\n",
        "    # draw rectangle\n",
        "    image = cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 0), 2)\n",
        "    # write class_id\n",
        "    image = cv2.putText(image, str(class_id), (bbox[0], bbox[1]-3), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "  \n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQhQtDS_Utxh"
      },
      "source": [
        "image = draw_image(\"TRAIN/TRAIN_0.jpg\")\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8lyhwc8Q24v"
      },
      "source": [
        "# Số lượng ảnh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7ruENnYQ5S9",
        "outputId": "1f9a2b5e-6d55-459e-b649-4f64291f8de9"
      },
      "source": [
        "list_image = glob2.glob(\"TRAIN/*.jpg\")\n",
        "list_annot = glob2.glob(\"TRAIN/*.txt\")\n",
        "\n",
        "print(\"number image: \", len(list_image))\n",
        "print(\"number annot: \", len(list_annot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number image:  2850\n",
            "number annot:  3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9XQL82YRl5y",
        "outputId": "4331eaea-db0c-4aa5-9978-801f6b37494a"
      },
      "source": [
        "list_image_png = glob2.glob(\"TRAIN/*.png\")\n",
        "\n",
        "print(\"number image png: \", len(list_image_png))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number image png:  150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCGlNQs7Xya9"
      },
      "source": [
        "# Xem thử các hình PNG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkM6PyH1YvjR"
      },
      "source": [
        "small_list = list_image_png[:20]\n",
        "for image_name in small_list:\n",
        "  image = draw_image(image_name)\n",
        "  image = imutils.resize(image)\n",
        "  cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeThUsZAZJeh"
      },
      "source": [
        "=> không loại bỏ đc các hình PNG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Weclz1ZMsk"
      },
      "source": [
        "# Gộp PNG và JPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmL2VTK-Zps5"
      },
      "source": [
        "for image_path in list_image_png:\n",
        "  list_image.append(image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6bp1BXzZaN7",
        "outputId": "902cac51-d6fb-44b0-8273-e9b5110eb5a8"
      },
      "source": [
        "print(\"number image: \", len(list_image))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number image:  3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkYvOmbPd8mi",
        "outputId": "3aa9ea82-0c9e-4d60-9ca7-f92826125d61"
      },
      "source": [
        "list_annot = []\n",
        "for image_path in list_image:\n",
        "  annot_path = (image_path.split(\"/\")[1]).split(\".\")[0] + \".txt\"\n",
        "  annot_path = os.path.join(\"TRAIN\", annot_path)\n",
        "\n",
        "  list_annot.append(annot_path)\n",
        "\n",
        "print(\"len list_annot: \", len(list_annot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len list_annot:  3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETrdTBeGkbHq"
      },
      "source": [
        "small_list = list_image[50:70]\n",
        "for image_name in small_list:\n",
        "  image = draw_image(image_name)\n",
        "  image = imutils.resize(image)\n",
        "  cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1DoX2IraYht"
      },
      "source": [
        "# Kiểm tra số lượng bbox và kich thước mỗi hình"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUVK1r70atNf"
      },
      "source": [
        "def get_number_box(annot_path, image_path, list_widths_bbox, list_heights_bbox):\n",
        "  list_info = []\n",
        "  image = cv2.imread(image_path)\n",
        "  \n",
        "  width, height, _ = image.shape\n",
        "\n",
        "  with open(annot_path) as f:\n",
        "    content = f.readlines()\n",
        "  \n",
        "  content = [x.strip() for x in content] \n",
        "  \n",
        "  file_name = image_path.split(\"/\")[1]\n",
        "  number_bb = len(content)\n",
        "\n",
        "  list_info = get_all_bboxes(annot_path)\n",
        "  for info in list_info:\n",
        "    class_id = info[0]\n",
        "    bbox = info[1]\n",
        "\n",
        "    w_bbox = bbox[2] - bbox[0]\n",
        "    h_bbox = bbox[3] - bbox[1]\n",
        "    list_widths_bbox.append(w_bbox)\n",
        "    list_heights_bbox.append(h_bbox)\n",
        "\n",
        "\n",
        "  return file_name, number_bb, width, height, list_widths_bbox, list_heights_bbox "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajXz25e3acH9",
        "outputId": "32054b54-67b8-4bb0-9286-093cd4fd8f28"
      },
      "source": [
        "list_file_names = []\n",
        "list_number_bb = []\n",
        "list_widths = []\n",
        "list_heights = []\n",
        "\n",
        "\n",
        "list_widths_bbox = []\n",
        "list_heights_bbox = []\n",
        "\n",
        "len_anno = len(list_annot)\n",
        "with tqdm(total=len_anno) as pbar:\n",
        "  for i in range(len_anno):\n",
        "    annot_path = list_annot[i]\n",
        "    image_path = list_image[i]\n",
        "\n",
        "    file_name, number_bb, width, height, list_w_bbox, list_h_bbox = get_number_box(annot_path, image_path, list_widths_bbox, list_heights_bbox)\n",
        "    list_widths_bbox = list_w_bbox\n",
        "    list_heights_bbox = list_h_bbox\n",
        "    list_file_names.append(file_name)\n",
        "    list_number_bb.append(number_bb)\n",
        "    list_widths.append(width)\n",
        "    list_heights.append(height)\n",
        "\n",
        "    pbar.update(1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [02:12<00:00, 22.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0NygXtXf3QR"
      },
      "source": [
        "count_bbox = {'file_name': list_file_names, 'width': list_widths, 'height': list_heights, 'number_bbox': list_number_bb}\n",
        "train_count_bbox = pd.DataFrame(data=count_bbox)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FntmgJC8gBPQ"
      },
      "source": [
        "train_count_bbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kKZZmHThU_u"
      },
      "source": [
        "image = draw_image(\"TRAIN/TRAIN_41.jpg\")\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPlsIkvqnM2X"
      },
      "source": [
        "size_distribute = {'w_bbox': list_widths_bbox, 'h_bbox': list_heights_bbox}\n",
        "size_distribute_df = pd.DataFrame(data=size_distribute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmurVwUjnsKf"
      },
      "source": [
        "size_distribute_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfny-EMtiem-"
      },
      "source": [
        "# Kiểm tra phân phối dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7wcSFpxiZvt"
      },
      "source": [
        "def hist_hover(dataframe, column, colors=[\"#94c8d8\"], bins=19, title=''):\n",
        "    hist, edges = np.histogram(dataframe[column], bins = bins)\n",
        "    \n",
        "    hist_df = pd.DataFrame({column: hist,\n",
        "                             \"left\": edges[:-1],\n",
        "                             \"right\": edges[1:]})\n",
        "    hist_df[\"interval\"] = [\"%d\" % left for left in hist_df[\"left\"]]\n",
        "\n",
        "    src = ColumnDataSource(hist_df)\n",
        "    plot = figure(plot_height = 400, plot_width = 800,\n",
        "          title = title,\n",
        "          x_axis_label = column,\n",
        "          y_axis_label = \"number of image\")    \n",
        "    plot.quad(bottom = 0, top = column,left = \"left\", \n",
        "        right = \"right\", source = src, fill_color = colors[0], \n",
        "        line_color = \"#35838d\", fill_alpha = 0.7,\n",
        "        hover_fill_alpha = 0.7, hover_fill_color = colors[0])\n",
        "        \n",
        "    hover = HoverTool(tooltips = [('Number of bbox', '@interval'),\n",
        "                              ('Count', str(\"@\" + column))])\n",
        "    plot.add_tools(hover)\n",
        "    \n",
        "    output_notebook()\n",
        "    show(plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1S_kg9EimJ6"
      },
      "source": [
        "hist_hover(train_count_bbox, 'number_bbox', title='Number of bbox per image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6y08Uubiw4P"
      },
      "source": [
        "hist_hover(train_count_bbox, 'width', title='Width of image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hD5ROJ3jDZr"
      },
      "source": [
        "hist_hover(train_count_bbox, 'height', title='height of image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyflqCVsjTCR"
      },
      "source": [
        "- Phân phối của width [600, 2000]\n",
        "- Phối phối của height [100, 2800]\n",
        "- => kết hợp lại thì điều kiện width hight sẽ trong khoảng là [600, 2100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz9TSrP9nxd9"
      },
      "source": [
        "# Kiểm tra phân phối của bounding box \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT7DzI4_n0wB"
      },
      "source": [
        "hist_hover(size_distribute_df, 'w_bbox', title='width of bbox')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYPBqQcYn64R"
      },
      "source": [
        "hist_hover(size_distribute_df, 'h_bbox', title='height of bbox')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txJS_2lcoTsq"
      },
      "source": [
        "Phần lớn logo có chiều dài là 150 => chọn width height trong vùng 150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJIDCWSpiKlh"
      },
      "source": [
        "# Loại bỏ bbox có kich thước lớn hơn 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUqfQu3YiNlg"
      },
      "source": [
        "def get_small_bbox(annot_path, image_path):\n",
        "  list_info = get_all_bboxes(annot_path)\n",
        "  image = cv2.imread(image_path)\n",
        "  image_name = (image_path.split(\"/\")[1]).split(\".\")[0]\n",
        "  list_new_info = []\n",
        "  for info in list_info:\n",
        "    class_id = info[0]\n",
        "    bbox = info[1]\n",
        "\n",
        "    w_bbox = bbox[2] - bbox[0]\n",
        "    h_bbox = bbox[3] - bbox[1]\n",
        "    \n",
        "    if w_bbox <= 150 and h_bbox <= 150:\n",
        "      info_box = [class_id, bbox]\n",
        "      list_new_info.append(info_box)\n",
        "  \n",
        "  return list_new_info, image, image_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwAaXWjFESL1",
        "outputId": "bbf166c1-8350-4904-c5eb-51843139643d"
      },
      "source": [
        "# create new_train\n",
        "new_train_dir = \"new_train\"\n",
        "if not os.path.exists(new_train_dir):\n",
        "  os.mkdir(new_train_dir)\n",
        "\n",
        "len_anno = len(list_annot)\n",
        "with tqdm(total=len_anno) as pbar:\n",
        "  for i in range(len_anno):\n",
        "    annot_path = list_annot[i]\n",
        "    image_path = list_image[i]\n",
        "\n",
        "    list_new_info, image, image_name = get_small_bbox(annot_path, image_path)\n",
        "    if len(list_new_info) != 0:\n",
        "      # save image\n",
        "      new_image_path = os.path.join(new_train_dir, image_name + '.jpg')\n",
        "      new_annot_path = os.path.join(new_train_dir, image_name + '.txt')\n",
        "      cv2.imwrite(new_image_path, image)\n",
        "      with open(new_annot_path, \"a+\") as f:\n",
        "        for info in list_new_info:\n",
        "          class_id = info[0]\n",
        "          bbox = info[1]\n",
        "          f.write(\"{} {} {} {} {}\\n\".format(class_id, bbox[0], bbox[1], bbox[2], bbox[3]))\n",
        "\n",
        "    pbar.update(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [02:52<00:00, 17.36it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDaHw5XtuGDc",
        "outputId": "b850c1e3-60d4-4054-ec5f-8cc063ed3285"
      },
      "source": [
        "new_list_image = glob2.glob(\"new_train/*.jpg\")\n",
        "new_list_annot = glob2.glob(\"new_train/*.txt\")\n",
        "\n",
        "print(\"number new list image: \", len(new_list_image))\n",
        "print(\"number new list annot: \", len(new_list_annot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number new list image:  993\n",
            "number new list annot:  993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKS3FqyAue44"
      },
      "source": [
        "small_list = new_list_image[40:60]\n",
        "for image_name in small_list:\n",
        "  image = draw_image(image_name)\n",
        "  image = imutils.resize(image)\n",
        "  cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWShBi5Z56KG"
      },
      "source": [
        "# Lưu lại dữ liệu đã xử lý"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--lazvVT8DmX"
      },
      "source": [
        "!zip -r new_train.zip new_train/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TedALPIlf7r"
      },
      "source": [
        "# Thống kê về diện tích"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNUL5SQJ4tUs"
      },
      "source": [
        "def get_area_box(annot_path, image_path, list_widths_bbox, list_heights_bbox, list_area_bbox):\n",
        "  list_info = []\n",
        "  image = cv2.imread(image_path)\n",
        "  \n",
        "  width, height, _ = image.shape\n",
        "\n",
        "  with open(annot_path) as f:\n",
        "    content = f.readlines()\n",
        "  \n",
        "  content = [x.strip() for x in content] \n",
        "  \n",
        "  file_name = image_path.split(\"/\")[1]\n",
        "  number_bb = len(content)\n",
        "\n",
        "  list_info = get_all_bboxes(annot_path)\n",
        "  for info in list_info:\n",
        "    class_id = info[0]\n",
        "    bbox = info[1]\n",
        "\n",
        "    w_bbox = bbox[2] - bbox[0]\n",
        "    h_bbox = bbox[3] - bbox[1]\n",
        "    list_widths_bbox.append(w_bbox)\n",
        "    list_heights_bbox.append(h_bbox)\n",
        "    list_area_bbox.append(w_bbox*h_bbox)\n",
        "\n",
        "\n",
        "  return file_name, number_bb, width, height, list_widths_bbox, list_heights_bbox, list_area_bbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_hzlAE45C20",
        "outputId": "081a2f93-36bb-4ddb-9c6c-8fc590cc2414"
      },
      "source": [
        "list_file_names = []\n",
        "list_number_bb = []\n",
        "list_widths = []\n",
        "list_heights = []\n",
        "list_area_bbox = []\n",
        "\n",
        "list_widths_bbox = []\n",
        "list_heights_bbox = []\n",
        "\n",
        "len_anno = len(new_list_annot)\n",
        "with tqdm(total=len_anno) as pbar:\n",
        "  for i in range(len_anno):\n",
        "    annot_path = new_list_annot[i]\n",
        "    image_path = new_list_image[i]\n",
        "\n",
        "    file_name, number_bb, width, height, list_w_bbox, list_h_bbox, list_area = get_area_box(annot_path, image_path, list_widths_bbox, list_heights_bbox, list_area_bbox)\n",
        "    list_widths_bbox = list_w_bbox\n",
        "    list_heights_bbox = list_h_bbox\n",
        "    list_area_bbox = list_area\n",
        "    list_file_names.append(file_name)\n",
        "    list_number_bb.append(number_bb)\n",
        "    list_widths.append(width)\n",
        "    list_heights.append(height)\n",
        "\n",
        "    pbar.update(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 993/993 [00:31<00:00, 31.06it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjeiuPs5X5n"
      },
      "source": [
        "new_train = {'w_bbox': list_widths_bbox, 'h_bbox': list_heights_bbox, 'area': list_area_bbox}\n",
        "new_train_df = pd.DataFrame(data=new_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjEQOn8u5fo9"
      },
      "source": [
        "new_train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_L9VcpZ5lee"
      },
      "source": [
        "hist_hover(new_train_df, 'area', title='area of bbox')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZImopdNmFLa"
      },
      "source": [
        "Đến đây cỡ bản là đã xong về phân tích dữ liệu rồi. Từ cell dưới sẽ là huấn luyện mô hình faster-RCNN trên detectron2 và submit kết quả."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9vd548EJMgY"
      },
      "source": [
        "# Package detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewq2hjAlJOby",
        "outputId": "99c20e8a-5146-4e81-f0a0-746da914f04e"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import random\n",
        "import glob2\n",
        "import itertools\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import detectron2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
        "from detectron2.structures import BoxMode\n",
        "from google.colab.patches import cv2_imshow\n",
        "from detectron2.data import detection_utils \n",
        "\n",
        "import detectron2.data.transforms as T\n",
        "\n",
        "import copy\n",
        "\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HJTkWDjJQtE",
        "outputId": "2b970bcd-82ec-4455-b8c4-51f36b3133de"
      },
      "source": [
        "anno_files = glob2.glob(os.path.join('new_train', \"*.txt\"))\n",
        "number = 80 * len(anno_files) // 100\n",
        "train_anno_files = anno_files[:number]\n",
        "val_anno_files = anno_files[number:]\n",
        "print(len(train_anno_files))\n",
        "print(len(val_anno_files))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "794\n",
            "199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZiaD8YWJSo5"
      },
      "source": [
        "def get_data_dicts_txt(anno_files):\n",
        "    classes = ['Logo_UIT', 'Logo_HSV', 'Logo_CS', 'Logo_CE', 'Logo_SE', 'Logo_ISE']\n",
        "    dataset_dicts = []    \n",
        "    count = 0\n",
        "    len_anno = len(anno_files)\n",
        "    print('len_anno: ', len_anno)\n",
        "    with tqdm(total=len_anno) as pbar:\n",
        "      for file_path in anno_files:\n",
        "          record = {}\n",
        "          try:\n",
        "            filename = file_path.split(\"/\")[-1]\n",
        "            filename = filename.split(\".\")[0]\n",
        "            img_path = os.path.join('new_train', filename + '.jpg')\n",
        "            height, width = cv2.imread(img_path).shape[:2]\n",
        "            \n",
        "            record[\"file_name\"] = img_path\n",
        "            record[\"image_id\"] = count\n",
        "            record[\"height\"] = height\n",
        "            record[\"width\"] = width\n",
        "\n",
        "            count += 1\n",
        "\n",
        "            annotations = open(file_path, 'r')\n",
        "            objs = []\n",
        "            for line in annotations:\n",
        "              line = line.rstrip('\\n')\n",
        "              # print(\"line: \", line)\n",
        "              class_id, x1, y1, x2, y2 = line.split()[:]\n",
        "\n",
        "              xmin = int(x1)\n",
        "              ymin = int(y1)\n",
        "              xmax = int(x2)\n",
        "              ymax = int(y2)\n",
        "\n",
        "              obj = {\n",
        "                    'bbox': [xmin, ymin, xmax, ymax],\n",
        "                    'bbox_mode': BoxMode.XYXY_ABS,\n",
        "                    'category_id': classes.index(classes[int(class_id)]),\n",
        "                    \"iscrowd\": 0\n",
        "              }\n",
        "              objs.append(obj)\n",
        "\n",
        "            record[\"annotations\"] = objs\n",
        "            dataset_dicts.append(record)\n",
        "            pbar.update(1)\n",
        "          except Exception as e:\n",
        "            print(e)\n",
        "            pass\n",
        "\n",
        "    return dataset_dicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP9sONfwJVpA"
      },
      "source": [
        "# get convert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVm2v9fRJWl3",
        "outputId": "cad5e894-3401-4768-c006-548eaa9ed31b"
      },
      "source": [
        "train_dicts = get_data_dicts_txt(train_anno_files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 6/794 [00:00<00:16, 47.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "len_anno:  794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 794/794 [00:29<00:00, 27.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KnPB4izJaH5",
        "outputId": "e4672248-8f67-4397-daa6-7db827186e34"
      },
      "source": [
        "val_dicts = get_data_dicts_txt(val_anno_files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 2/199 [00:00<00:12, 15.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "len_anno:  199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 199/199 [00:07<00:00, 28.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W83uj7LJggE"
      },
      "source": [
        "with open('train.json', 'w') as fp:\n",
        "    json.dump(train_dicts, fp)\n",
        "\n",
        "with open('val.json', 'w') as fp:\n",
        "    json.dump(val_dicts, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZKtI5F-JlDX"
      },
      "source": [
        "# Load json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7L7Zr5hJmOE"
      },
      "source": [
        "# with open('val_receipt.json', 'r') as fp:\n",
        "#     val_dicts = json.load(fp)\n",
        "\n",
        "# with open('train_receipt.json', 'r') as fp:\n",
        "#     train_dicts = json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JznAY8OwJo06"
      },
      "source": [
        "# View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bTVwIhVJpp6"
      },
      "source": [
        "for i in range(len(val_dicts)):\n",
        "  for j in range(len(val_dicts[i][\"annotations\"])):\n",
        "      val_dicts[i][\"annotations\"][j]['bbox_mode'] = BoxMode.XYXY_ABS\n",
        "for i in range(len(train_dicts)):\n",
        "  for j in range(len(train_dicts[i][\"annotations\"])):\n",
        "      train_dicts[i][\"annotations\"][j]['bbox_mode'] = BoxMode.XYXY_ABS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iqsIyvtJr1o"
      },
      "source": [
        "classes = ['Logo_UIT', 'Logo_HSV', 'Logo_CS', 'Logo_CE', 'Logo_SE', 'Logo_ISE']\n",
        "data = [train_dicts, val_dicts]\n",
        "\n",
        "for index, d in enumerate([\"train\", \"val\"]):\n",
        "  DatasetCatalog.register(\"logouit_data/\" + d, lambda index=index: data[index])\n",
        "  MetadataCatalog.get(\"logouit_data/\" + d).set(thing_classes=classes)\n",
        "logo_metadata = MetadataCatalog.get(\"logouit_data/train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qupYKNn2J92r"
      },
      "source": [
        "# Custom mapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCSdRlLJ-UV"
      },
      "source": [
        "class CustomTrainer(DefaultTrainer):\n",
        "  \n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"detectron_eval\", exist_ok=True) # name dir\n",
        "        output_folder = \"detectron_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f08FVORKKBNd"
      },
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for d in random.sample(val_dicts, 2):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    v = Visualizer(img[:, :, ::-1], metadata=logo_metadata, scale=0.5)\n",
        "    v = v.draw_dataset_dict(d)\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhH_cwtYKTeC"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nST13jIKRIe",
        "outputId": "b86b69e0-f451-4384-a084-3912c4f76339"
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"./detectron2/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"logouit_data/train\",)\n",
        "cfg.DATASETS.TEST = (\"logouit_data/val\",)   # no metrics implemented for this dataset\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "\n",
        "#https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\"  # initialize from model zoo\n",
        "# cfg.MODEL.WEIGHTS = \"faster_rcnn_R_101_FPN_3x_model/model_final.pth\"\n",
        "print(\"CHECK WEIGHTS: \", cfg.MODEL.WEIGHTS)\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.0001\n",
        "cfg.SOLVER.MAX_ITER = 3000 # 3k\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 4\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\n",
        "cfg.OUTPUT_DIR = \"./faster_rcnn_R_101_FPN_3x_model\"\n",
        "\n",
        "cfg.TEST.EVAL_PERIOD = 1000\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = CustomTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHECK WEIGHTS:  faster_rcnn_R_101_FPN_3x_model/model_final.pth\n",
            "\u001b[32m[12/20 13:26:55 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[12/20 13:26:55 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 794 images left.\n",
            "\u001b[32m[12/20 13:26:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[12/20 13:26:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[12/20 13:26:55 d2.data.common]: \u001b[0mSerializing 794 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/20 13:26:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.20 MiB\n",
            "\u001b[32m[12/20 13:26:55 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[12/20 13:27:05 d2.utils.events]: \u001b[0m eta: 0:14:15  iter: 19  total_loss: 0.5115  loss_cls: 0.09854  loss_box_reg: 0.2595  loss_rpn_cls: 0.02589  loss_rpn_loc: 0.0111  time: 0.4271  data_time: 0.0644  lr: 1.9981e-06  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:27:13 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 39  total_loss: 0.6058  loss_cls: 0.1549  loss_box_reg: 0.3471  loss_rpn_cls: 0.02176  loss_rpn_loc: 0.01516  time: 0.4238  data_time: 0.0252  lr: 3.9961e-06  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:27:22 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 59  total_loss: 0.52  loss_cls: 0.2365  loss_box_reg: 0.2837  loss_rpn_cls: 0.02918  loss_rpn_loc: 0.01339  time: 0.4379  data_time: 0.0447  lr: 5.9941e-06  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:27:31 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 79  total_loss: 0.5904  loss_cls: 0.1734  loss_box_reg: 0.2964  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.009526  time: 0.4365  data_time: 0.0321  lr: 7.9921e-06  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:27:41 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 99  total_loss: 0.6752  loss_cls: 0.2553  loss_box_reg: 0.2821  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.02045  time: 0.4494  data_time: 0.0590  lr: 9.9901e-06  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:27:50 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 119  total_loss: 0.535  loss_cls: 0.2251  loss_box_reg: 0.3071  loss_rpn_cls: 0.03512  loss_rpn_loc: 0.01607  time: 0.4494  data_time: 0.0186  lr: 1.1988e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:27:59 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 139  total_loss: 0.4599  loss_cls: 0.03043  loss_box_reg: 0.2945  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.01511  time: 0.4503  data_time: 0.0515  lr: 1.3986e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:28:09 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 159  total_loss: 0.3833  loss_cls: 0.1613  loss_box_reg: 0.2129  loss_rpn_cls: 0.01633  loss_rpn_loc: 0.01033  time: 0.4517  data_time: 0.0210  lr: 1.5984e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:28:18 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 179  total_loss: 0.662  loss_cls: 0.2969  loss_box_reg: 0.2438  loss_rpn_cls: 0.02308  loss_rpn_loc: 0.01722  time: 0.4515  data_time: 0.0268  lr: 1.7982e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:28:26 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 199  total_loss: 0.6261  loss_cls: 0.1874  loss_box_reg: 0.3385  loss_rpn_cls: 0.02278  loss_rpn_loc: 0.0108  time: 0.4496  data_time: 0.0352  lr: 1.998e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:28:34 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 219  total_loss: 0.4798  loss_cls: 0.1793  loss_box_reg: 0.2661  loss_rpn_cls: 0.02348  loss_rpn_loc: 0.01035  time: 0.4463  data_time: 0.0118  lr: 2.1978e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:28:43 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 239  total_loss: 0.6578  loss_cls: 0.1986  loss_box_reg: 0.3818  loss_rpn_cls: 0.03542  loss_rpn_loc: 0.02219  time: 0.4462  data_time: 0.0488  lr: 2.3976e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:28:52 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 259  total_loss: 0.5777  loss_cls: 0.212  loss_box_reg: 0.3771  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.007515  time: 0.4465  data_time: 0.0372  lr: 2.5974e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:29:01 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 279  total_loss: 0.6372  loss_cls: 0.107  loss_box_reg: 0.3122  loss_rpn_cls: 0.02006  loss_rpn_loc: 0.007403  time: 0.4443  data_time: 0.0110  lr: 2.7972e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:29:10 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 299  total_loss: 0.5286  loss_cls: 0.1327  loss_box_reg: 0.2602  loss_rpn_cls: 0.02436  loss_rpn_loc: 0.01352  time: 0.4445  data_time: 0.0197  lr: 2.997e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:29:18 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 319  total_loss: 0.536  loss_cls: 0.2053  loss_box_reg: 0.2307  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.01051  time: 0.4439  data_time: 0.0302  lr: 3.1968e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:29:28 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 339  total_loss: 0.6755  loss_cls: 0.2275  loss_box_reg: 0.2471  loss_rpn_cls: 0.03273  loss_rpn_loc: 0.03791  time: 0.4445  data_time: 0.0410  lr: 3.3966e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:29:36 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 359  total_loss: 0.5565  loss_cls: 0.07314  loss_box_reg: 0.2909  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.00959  time: 0.4433  data_time: 0.0112  lr: 3.5964e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:29:44 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 379  total_loss: 0.6563  loss_cls: 0.2127  loss_box_reg: 0.2065  loss_rpn_cls: 0.02815  loss_rpn_loc: 0.01192  time: 0.4418  data_time: 0.0303  lr: 3.7962e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:29:53 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 399  total_loss: 0.4782  loss_cls: 0.1717  loss_box_reg: 0.228  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.006656  time: 0.4412  data_time: 0.0236  lr: 3.996e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:30:02 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 419  total_loss: 0.7136  loss_cls: 0.1844  loss_box_reg: 0.2591  loss_rpn_cls: 0.0219  loss_rpn_loc: 0.01649  time: 0.4427  data_time: 0.0714  lr: 4.1958e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:30:11 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 439  total_loss: 0.481  loss_cls: 0.1802  loss_box_reg: 0.2774  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.01575  time: 0.4409  data_time: 0.0087  lr: 4.3956e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:30:19 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 459  total_loss: 0.4393  loss_cls: 0.1072  loss_box_reg: 0.2375  loss_rpn_cls: 0.02363  loss_rpn_loc: 0.009341  time: 0.4397  data_time: 0.0110  lr: 4.5954e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:30:27 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 479  total_loss: 0.507  loss_cls: 0.1129  loss_box_reg: 0.3301  loss_rpn_cls: 0.0189  loss_rpn_loc: 0.01016  time: 0.4391  data_time: 0.0165  lr: 4.7952e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:30:37 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 499  total_loss: 0.6139  loss_cls: 0.1684  loss_box_reg: 0.2736  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.009952  time: 0.4401  data_time: 0.0481  lr: 4.995e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:30:46 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 519  total_loss: 0.5566  loss_cls: 0.1026  loss_box_reg: 0.2311  loss_rpn_cls: 0.02406  loss_rpn_loc: 0.01352  time: 0.4402  data_time: 0.0357  lr: 5.1948e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:30:54 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 539  total_loss: 0.49  loss_cls: 0.1207  loss_box_reg: 0.2526  loss_rpn_cls: 0.02061  loss_rpn_loc: 0.00979  time: 0.4391  data_time: 0.0155  lr: 5.3946e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:31:02 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 559  total_loss: 0.5564  loss_cls: 0.2378  loss_box_reg: 0.2966  loss_rpn_cls: 0.01971  loss_rpn_loc: 0.01721  time: 0.4389  data_time: 0.0252  lr: 5.5944e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:31:11 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 579  total_loss: 0.5526  loss_cls: 0.2255  loss_box_reg: 0.2448  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.0186  time: 0.4393  data_time: 0.0386  lr: 5.7942e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:31:20 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 599  total_loss: 0.561  loss_cls: 0.2369  loss_box_reg: 0.325  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.01571  time: 0.4389  data_time: 0.0106  lr: 5.994e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:31:30 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 619  total_loss: 0.6153  loss_cls: 0.2006  loss_box_reg: 0.2939  loss_rpn_cls: 0.02389  loss_rpn_loc: 0.009517  time: 0.4407  data_time: 0.0558  lr: 6.1938e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:31:39 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 639  total_loss: 0.4971  loss_cls: 0.1485  loss_box_reg: 0.3389  loss_rpn_cls: 0.01596  loss_rpn_loc: 0.01309  time: 0.4409  data_time: 0.0388  lr: 6.3936e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:31:47 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 659  total_loss: 0.4243  loss_cls: 0.1757  loss_box_reg: 0.1904  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.008732  time: 0.4399  data_time: 0.0207  lr: 6.5934e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:31:57 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 679  total_loss: 0.6515  loss_cls: 0.08414  loss_box_reg: 0.3048  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.02558  time: 0.4413  data_time: 0.0587  lr: 6.7932e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:32:06 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 699  total_loss: 0.5379  loss_cls: 0.2215  loss_box_reg: 0.2155  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.007366  time: 0.4409  data_time: 0.0114  lr: 6.993e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:32:14 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 719  total_loss: 0.4602  loss_cls: 0.1083  loss_box_reg: 0.2389  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.01181  time: 0.4403  data_time: 0.0337  lr: 7.1928e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:32:23 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 739  total_loss: 0.5185  loss_cls: 0.2691  loss_box_reg: 0.2222  loss_rpn_cls: 0.02434  loss_rpn_loc: 0.01537  time: 0.4403  data_time: 0.0112  lr: 7.3926e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:32:33 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 759  total_loss: 0.577  loss_cls: 0.1916  loss_box_reg: 0.2662  loss_rpn_cls: 0.01924  loss_rpn_loc: 0.01625  time: 0.4416  data_time: 0.0522  lr: 7.5924e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:32:41 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 779  total_loss: 0.5077  loss_cls: 0.1167  loss_box_reg: 0.1839  loss_rpn_cls: 0.02677  loss_rpn_loc: 0.008122  time: 0.4412  data_time: 0.0153  lr: 7.7922e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:32:49 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 799  total_loss: 0.5684  loss_cls: 0.2422  loss_box_reg: 0.283  loss_rpn_cls: 0.02353  loss_rpn_loc: 0.01187  time: 0.4402  data_time: 0.0085  lr: 7.992e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:32:58 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 819  total_loss: 0.4993  loss_cls: 0.1206  loss_box_reg: 0.2958  loss_rpn_cls: 0.0201  loss_rpn_loc: 0.01079  time: 0.4400  data_time: 0.0095  lr: 8.1918e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:33:08 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 839  total_loss: 0.4958  loss_cls: 0.09126  loss_box_reg: 0.3205  loss_rpn_cls: 0.04225  loss_rpn_loc: 0.01984  time: 0.4411  data_time: 0.0517  lr: 8.3916e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:33:16 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 859  total_loss: 0.5205  loss_cls: 0.1683  loss_box_reg: 0.301  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.0119  time: 0.4403  data_time: 0.0164  lr: 8.5914e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:33:25 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 879  total_loss: 0.3989  loss_cls: 0.12  loss_box_reg: 0.2274  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.007547  time: 0.4410  data_time: 0.0588  lr: 8.7912e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:33:34 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 899  total_loss: 0.5664  loss_cls: 0.09613  loss_box_reg: 0.3019  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.00946  time: 0.4414  data_time: 0.0476  lr: 8.991e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:33:43 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 919  total_loss: 0.893  loss_cls: 0.263  loss_box_reg: 0.2961  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.01594  time: 0.4413  data_time: 0.0131  lr: 9.1908e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:33:52 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 939  total_loss: 0.5419  loss_cls: 0.185  loss_box_reg: 0.3165  loss_rpn_cls: 0.03101  loss_rpn_loc: 0.01412  time: 0.4411  data_time: 0.0179  lr: 9.3906e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:34:00 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 959  total_loss: 0.5859  loss_cls: 0.09681  loss_box_reg: 0.2901  loss_rpn_cls: 0.01352  loss_rpn_loc: 0.02142  time: 0.4409  data_time: 0.0330  lr: 9.5904e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:34:10 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 979  total_loss: 0.509  loss_cls: 0.2186  loss_box_reg: 0.2598  loss_rpn_cls: 0.02884  loss_rpn_loc: 0.01427  time: 0.4414  data_time: 0.0480  lr: 9.7902e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:34:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[12/20 13:34:19 d2.data.common]: \u001b[0mSerializing 199 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/20 13:34:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/20 13:34:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[12/20 13:34:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 199 images\n",
            "\u001b[32m[12/20 13:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/199. 0.1105 s / img. ETA=0:00:21\n",
            "\u001b[32m[12/20 13:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 48/199. 0.1204 s / img. ETA=0:00:20\n",
            "\u001b[32m[12/20 13:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 77/199. 0.1256 s / img. ETA=0:00:18\n",
            "\u001b[32m[12/20 13:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 115/199. 0.1225 s / img. ETA=0:00:12\n",
            "\u001b[32m[12/20 13:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 151/199. 0.1222 s / img. ETA=0:00:06\n",
            "\u001b[32m[12/20 13:34:47 d2.evaluation.evaluator]: \u001b[0mInference done 183/199. 0.1217 s / img. ETA=0:00:02\n",
            "\u001b[32m[12/20 13:34:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.269284 (0.145718 s / img per device, on 1 devices)\n",
            "\u001b[32m[12/20 13:34:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:23 (0.120979 s / img per device, on 1 devices)\n",
            "\u001b[32m[12/20 13:34:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[12/20 13:34:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to detectron_eval/coco_instances_results.json\n",
            "\u001b[32m[12/20 13:34:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.47 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.453\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
            "\u001b[32m[12/20 13:34:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 30.411 | 45.276 | 33.899 | 16.766 | 32.090 | 39.480 |\n",
            "\u001b[32m[12/20 13:34:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Logo_UIT   | 49.079 | Logo_HSV   | 63.350 | Logo_CS    | 14.096 |\n",
            "| Logo_CE    | 22.068 | Logo_SE    | 33.836 | Logo_ISE   | 0.035  |\n",
            "\u001b[32m[12/20 13:34:50 d2.engine.defaults]: \u001b[0mEvaluation results for logouit_data/val in csv format:\n",
            "\u001b[32m[12/20 13:34:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[12/20 13:34:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[12/20 13:34:50 d2.evaluation.testing]: \u001b[0mcopypaste: 30.4107,45.2756,33.8994,16.7661,32.0897,39.4796\n",
            "\u001b[32m[12/20 13:34:50 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 999  total_loss: 0.6168  loss_cls: 0.2561  loss_box_reg: 0.2119  loss_rpn_cls: 0.03979  loss_rpn_loc: 0.02562  time: 0.4417  data_time: 0.0230  lr: 9.99e-05  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:34:58 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1019  total_loss: 0.6952  loss_cls: 0.3454  loss_box_reg: 0.2974  loss_rpn_cls: 0.02508  loss_rpn_loc: 0.0119  time: 0.4416  data_time: 0.0319  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:35:07 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 1039  total_loss: 0.5182  loss_cls: 0.1442  loss_box_reg: 0.2853  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.008411  time: 0.4414  data_time: 0.0239  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:35:16 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 1059  total_loss: 0.5556  loss_cls: 0.2652  loss_box_reg: 0.2286  loss_rpn_cls: 0.03435  loss_rpn_loc: 0.007102  time: 0.4410  data_time: 0.0162  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:35:24 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 1079  total_loss: 0.4451  loss_cls: 0.07742  loss_box_reg: 0.332  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01159  time: 0.4404  data_time: 0.0168  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:35:32 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1099  total_loss: 0.5092  loss_cls: 0.1889  loss_box_reg: 0.3143  loss_rpn_cls: 0.02234  loss_rpn_loc: 0.01268  time: 0.4399  data_time: 0.0263  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:35:41 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 1119  total_loss: 0.5975  loss_cls: 0.1255  loss_box_reg: 0.3068  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.01246  time: 0.4399  data_time: 0.0283  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:35:50 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1139  total_loss: 0.4706  loss_cls: 0.09475  loss_box_reg: 0.2397  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.01383  time: 0.4401  data_time: 0.0374  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:35:59 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 1159  total_loss: 0.6369  loss_cls: 0.2379  loss_box_reg: 0.3204  loss_rpn_cls: 0.03548  loss_rpn_loc: 0.01389  time: 0.4401  data_time: 0.0318  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:36:08 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1179  total_loss: 0.5682  loss_cls: 0.1146  loss_box_reg: 0.3228  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.01295  time: 0.4401  data_time: 0.0220  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:36:16 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 1199  total_loss: 0.5055  loss_cls: 0.1084  loss_box_reg: 0.3511  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.01411  time: 0.4402  data_time: 0.0400  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:36:25 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1219  total_loss: 0.6582  loss_cls: 0.2402  loss_box_reg: 0.3308  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.02001  time: 0.4398  data_time: 0.0088  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:36:34 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 1239  total_loss: 0.4663  loss_cls: 0.1782  loss_box_reg: 0.2614  loss_rpn_cls: 0.02175  loss_rpn_loc: 0.01029  time: 0.4398  data_time: 0.0186  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:36:42 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 1259  total_loss: 0.5186  loss_cls: 0.2104  loss_box_reg: 0.199  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.01157  time: 0.4397  data_time: 0.0185  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:36:51 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 1279  total_loss: 0.5381  loss_cls: 0.2568  loss_box_reg: 0.2388  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.01129  time: 0.4393  data_time: 0.0172  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:36:59 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 1299  total_loss: 0.3989  loss_cls: 0.06189  loss_box_reg: 0.2844  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.008098  time: 0.4389  data_time: 0.0084  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:37:08 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 1319  total_loss: 0.5198  loss_cls: 0.08976  loss_box_reg: 0.3187  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.01599  time: 0.4391  data_time: 0.0323  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:37:17 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 1339  total_loss: 0.5255  loss_cls: 0.1951  loss_box_reg: 0.276  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.008371  time: 0.4393  data_time: 0.0223  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:37:25 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 1359  total_loss: 0.6888  loss_cls: 0.2655  loss_box_reg: 0.2935  loss_rpn_cls: 0.02748  loss_rpn_loc: 0.009531  time: 0.4388  data_time: 0.0082  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:37:34 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 1379  total_loss: 0.538  loss_cls: 0.1016  loss_box_reg: 0.2362  loss_rpn_cls: 0.03601  loss_rpn_loc: 0.01107  time: 0.4387  data_time: 0.0321  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:37:42 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 1399  total_loss: 0.6411  loss_cls: 0.2998  loss_box_reg: 0.1995  loss_rpn_cls: 0.02903  loss_rpn_loc: 0.01515  time: 0.4383  data_time: 0.0149  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:37:50 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 1419  total_loss: 0.5413  loss_cls: 0.2607  loss_box_reg: 0.3085  loss_rpn_cls: 0.02442  loss_rpn_loc: 0.0151  time: 0.4381  data_time: 0.0240  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:37:59 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 1439  total_loss: 0.6317  loss_cls: 0.1493  loss_box_reg: 0.3532  loss_rpn_cls: 0.02096  loss_rpn_loc: 0.01104  time: 0.4379  data_time: 0.0219  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:38:08 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 1459  total_loss: 0.611  loss_cls: 0.3002  loss_box_reg: 0.2803  loss_rpn_cls: 0.03504  loss_rpn_loc: 0.01249  time: 0.4379  data_time: 0.0237  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:38:17 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 1479  total_loss: 0.5389  loss_cls: 0.1634  loss_box_reg: 0.2727  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.01148  time: 0.4380  data_time: 0.0390  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:38:26 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 1499  total_loss: 0.4905  loss_cls: 0.06791  loss_box_reg: 0.3451  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.01486  time: 0.4380  data_time: 0.0378  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:38:35 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 1519  total_loss: 0.5968  loss_cls: 0.2531  loss_box_reg: 0.3772  loss_rpn_cls: 0.02413  loss_rpn_loc: 0.01528  time: 0.4384  data_time: 0.0590  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:38:44 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1539  total_loss: 0.5373  loss_cls: 0.2696  loss_box_reg: 0.2803  loss_rpn_cls: 0.03376  loss_rpn_loc: 0.01337  time: 0.4383  data_time: 0.0313  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:38:53 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 1559  total_loss: 0.5274  loss_cls: 0.1267  loss_box_reg: 0.2992  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.008207  time: 0.4385  data_time: 0.0240  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:39:02 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 1579  total_loss: 0.4739  loss_cls: 0.09299  loss_box_reg: 0.3054  loss_rpn_cls: 0.01605  loss_rpn_loc: 0.01245  time: 0.4387  data_time: 0.0477  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:39:10 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 1599  total_loss: 0.4727  loss_cls: 0.1244  loss_box_reg: 0.2843  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.008415  time: 0.4386  data_time: 0.0217  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:39:19 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 1619  total_loss: 0.6203  loss_cls: 0.2196  loss_box_reg: 0.3371  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.01587  time: 0.4388  data_time: 0.0231  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:39:28 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 1639  total_loss: 0.4889  loss_cls: 0.07863  loss_box_reg: 0.2781  loss_rpn_cls: 0.01602  loss_rpn_loc: 0.0114  time: 0.4387  data_time: 0.0250  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:39:37 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 1659  total_loss: 0.4929  loss_cls: 0.1209  loss_box_reg: 0.3572  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.00808  time: 0.4390  data_time: 0.0231  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:39:46 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 1679  total_loss: 0.6424  loss_cls: 0.146  loss_box_reg: 0.2381  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.01431  time: 0.4388  data_time: 0.0196  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:39:54 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 1699  total_loss: 0.6224  loss_cls: 0.2145  loss_box_reg: 0.2693  loss_rpn_cls: 0.03542  loss_rpn_loc: 0.01425  time: 0.4386  data_time: 0.0215  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:40:03 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 1719  total_loss: 0.5335  loss_cls: 0.0728  loss_box_reg: 0.3137  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.009667  time: 0.4382  data_time: 0.0106  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:40:11 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1739  total_loss: 0.3666  loss_cls: 0.06379  loss_box_reg: 0.1714  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.009741  time: 0.4382  data_time: 0.0247  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:40:20 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 1759  total_loss: 0.5931  loss_cls: 0.375  loss_box_reg: 0.3064  loss_rpn_cls: 0.02551  loss_rpn_loc: 0.01811  time: 0.4381  data_time: 0.0236  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:40:29 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 1779  total_loss: 0.5936  loss_cls: 0.171  loss_box_reg: 0.3063  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.01647  time: 0.4384  data_time: 0.0402  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:40:38 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 1799  total_loss: 0.4451  loss_cls: 0.05651  loss_box_reg: 0.2864  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.01008  time: 0.4383  data_time: 0.0141  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:40:47 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 1819  total_loss: 0.4798  loss_cls: 0.08484  loss_box_reg: 0.2628  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.009524  time: 0.4382  data_time: 0.0177  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:40:55 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 1839  total_loss: 0.8629  loss_cls: 0.3587  loss_box_reg: 0.2411  loss_rpn_cls: 0.03153  loss_rpn_loc: 0.01633  time: 0.4382  data_time: 0.0260  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:41:04 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 1859  total_loss: 0.6173  loss_cls: 0.1946  loss_box_reg: 0.2735  loss_rpn_cls: 0.04835  loss_rpn_loc: 0.02586  time: 0.4383  data_time: 0.0336  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:41:13 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 1879  total_loss: 0.5633  loss_cls: 0.2654  loss_box_reg: 0.2564  loss_rpn_cls: 0.03728  loss_rpn_loc: 0.02203  time: 0.4381  data_time: 0.0255  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:41:23 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 1899  total_loss: 0.5391  loss_cls: 0.1477  loss_box_reg: 0.2613  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.00669  time: 0.4388  data_time: 0.0516  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:41:32 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 1919  total_loss: 0.569  loss_cls: 0.2985  loss_box_reg: 0.1932  loss_rpn_cls: 0.03031  loss_rpn_loc: 0.01556  time: 0.4391  data_time: 0.0395  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:41:41 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 1939  total_loss: 0.6139  loss_cls: 0.2127  loss_box_reg: 0.2428  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.01774  time: 0.4393  data_time: 0.0525  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:41:50 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 1959  total_loss: 0.5717  loss_cls: 0.2731  loss_box_reg: 0.2623  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.01206  time: 0.4391  data_time: 0.0217  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:41:59 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 1979  total_loss: 0.4677  loss_cls: 0.07244  loss_box_reg: 0.3277  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.006263  time: 0.4395  data_time: 0.0604  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:42:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[12/20 13:42:10 d2.data.common]: \u001b[0mSerializing 199 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/20 13:42:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/20 13:42:10 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[12/20 13:42:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 199 images\n",
            "\u001b[32m[12/20 13:42:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/199. 0.1101 s / img. ETA=0:00:20\n",
            "\u001b[32m[12/20 13:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 49/199. 0.1137 s / img. ETA=0:00:19\n",
            "\u001b[32m[12/20 13:42:22 d2.evaluation.evaluator]: \u001b[0mInference done 79/199. 0.1200 s / img. ETA=0:00:17\n",
            "\u001b[32m[12/20 13:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 118/199. 0.1175 s / img. ETA=0:00:11\n",
            "\u001b[32m[12/20 13:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 153/199. 0.1190 s / img. ETA=0:00:06\n",
            "\u001b[32m[12/20 13:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 184/199. 0.1205 s / img. ETA=0:00:02\n",
            "\u001b[32m[12/20 13:42:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.906922 (0.143850 s / img per device, on 1 devices)\n",
            "\u001b[32m[12/20 13:42:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:23 (0.119367 s / img per device, on 1 devices)\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to detectron_eval/coco_instances_results.json\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.21 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.524\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.424\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 33.640 | 52.404 | 40.597 | 16.997 | 37.354 | 40.730 |\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Logo_UIT   | 49.446 | Logo_HSV   | 60.605 | Logo_CS    | 22.536 |\n",
            "| Logo_CE    | 28.407 | Logo_SE    | 32.526 | Logo_ISE   | 8.317  |\n",
            "\u001b[32m[12/20 13:42:40 d2.engine.defaults]: \u001b[0mEvaluation results for logouit_data/val in csv format:\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.testing]: \u001b[0mcopypaste: 33.6395,52.4038,40.5974,16.9973,37.3537,40.7303\n",
            "\u001b[32m[12/20 13:42:40 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1999  total_loss: 0.544  loss_cls: 0.1166  loss_box_reg: 0.2268  loss_rpn_cls: 0.02265  loss_rpn_loc: 0.01731  time: 0.4394  data_time: 0.0243  lr: 0.0001  max_mem: 4020M\n",
            "\u001b[32m[12/20 13:42:40 d2.engine.hooks]: \u001b[0mOverall training speed: 1998 iterations in 0:14:38 (0.4394 s / it)\n",
            "\u001b[32m[12/20 13:42:40 d2.engine.hooks]: \u001b[0mTotal training time: 0:15:43 (0:01:04 on hooks)\n",
            "\u001b[32m[12/20 13:42:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[12/20 13:42:40 d2.data.common]: \u001b[0mSerializing 199 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/20 13:42:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/20 13:42:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[12/20 13:42:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 199 images\n",
            "\u001b[32m[12/20 13:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 14/199. 0.1121 s / img. ETA=0:00:21\n",
            "\u001b[32m[12/20 13:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 52/199. 0.1148 s / img. ETA=0:00:19\n",
            "\u001b[32m[12/20 13:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 82/199. 0.1240 s / img. ETA=0:00:16\n",
            "\u001b[32m[12/20 13:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 120/199. 0.1218 s / img. ETA=0:00:11\n",
            "\u001b[32m[12/20 13:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 156/199. 0.1203 s / img. ETA=0:00:06\n",
            "\u001b[32m[12/20 13:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 186/199. 0.1211 s / img. ETA=0:00:01\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.984952 (0.144252 s / img per device, on 1 devices)\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:23 (0.120600 s / img per device, on 1 devices)\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to detectron_eval/coco_instances_results.json\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.22 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.524\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.424\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 33.640 | 52.404 | 40.597 | 16.997 | 37.354 | 40.730 |\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| Logo_UIT   | 49.446 | Logo_HSV   | 60.605 | Logo_CS    | 22.536 |\n",
            "| Logo_CE    | 28.407 | Logo_SE    | 32.526 | Logo_ISE   | 8.317  |\n",
            "\u001b[32m[12/20 13:43:10 d2.engine.defaults]: \u001b[0mEvaluation results for logouit_data/val in csv format:\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[12/20 13:43:10 d2.evaluation.testing]: \u001b[0mcopypaste: 33.6395,52.4038,40.5974,16.9973,37.3537,40.7303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAl1hb7KL-tJ"
      },
      "source": [
        "# predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TABUngeL_rV"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, evaluator\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.structures import BoxMode\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import json\n",
        "\n",
        "def predict (path_weigths, path_config, confidence_threshold, num_of_class, path_img):\n",
        "  cfg = get_cfg()\n",
        "  cfg.merge_from_file(path_config)\n",
        "  cfg.MODEL.WEIGHTS = path_weigths\n",
        "\n",
        "  #cfg.MODEL.WEIGHTS = \"mask_rcnn_R_50_FPN_3x_model/model_final.pth\"\n",
        "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = confidence_threshold\n",
        "  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 8   \n",
        "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_of_class \n",
        "  predictor = DefaultPredictor(cfg)\n",
        "  im = cv2.imread(path_img)\n",
        "  outputs = predictor(im)\n",
        "  \n",
        "  return outputs\n",
        "\n",
        "#Đầu vào detect = output của hàm predict, frame = original image của mình, classs = tên class để visualize\n",
        "def visualize (out, frame, classs):\n",
        "  boxes = out['instances'].pred_boxes\n",
        "  scores = out['instances'].scores\n",
        "  classes = out['instances'].pred_classes\n",
        "  for i in range (len(classes)):\n",
        "    if (scores[i] > 0.4):\n",
        "      for j in boxes[i]:\n",
        "        start = (int (j[0]), int (j[1]))\n",
        "        end = (int (j[2]), int (j[3]))\n",
        "        print (start)\n",
        "        print (end)\n",
        "        width =  end[0] - start[0]\n",
        "        height = end[1] - start[1]\n",
        "        print ('width:', width)\n",
        "        print ('height:', height)\n",
        "        print('class:', int (classes[i]))\n",
        "        print('score:', float (scores[i]))\n",
        "        print ('---------------------', start, end, scores[i], classes[i])\n",
        "      color = int (classes[i])\n",
        "      print (classes[i])\n",
        "        \n",
        "      cv2.rectangle(frame, start, end, (random.randint(0,255),random.randint(0,255),255), 3)\n",
        "      cv2.putText(frame, str (classs[color]),start, cv2.FONT_HERSHEY_PLAIN, 1, (random.randint(0,255),random.randint(0,255),255), 2)\n",
        "  return frame\n",
        "\n",
        "\n",
        "path_weigth = \"faster_rcnn_R_101_FPN_3x_model/model_final.pth\"\n",
        "path_config = \"./detectron2/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"\n",
        "confidences_threshold = 0.4\n",
        "num_of_class = 5\n",
        "path_img = 'new_train/TRAIN_0.jpg'\n",
        "classes = ['Logo_UIT', 'Logo_HSV', 'Logo_CS', 'Logo_CE', 'Logo_SE', 'Logo_ISE']\n",
        "outputs = predict(path_weigth, path_config, confidences_threshold, num_of_class, path_img)\n",
        "print(outputs)\n",
        "_frame = cv2.imread(path_img)\n",
        "frame = visualize (outputs, _frame, classes )\n",
        "# cv2.imwrite(\"frame.jpg\", frame)\n",
        "cv2_imshow(frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnkihmhdLL0t"
      },
      "source": [
        "# Submit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZZikUPiLvhp",
        "outputId": "25f0ea3d-45bc-46d2-dcee-a64fcaa0af39"
      },
      "source": [
        "!gdown --id 1Ng8UWSg2XNMWS49qhchTz24wSfE80cfA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ng8UWSg2XNMWS49qhchTz24wSfE80cfA\n",
            "To: /content/WARM_UP.zip\n",
            "370MB [00:02, 182MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU690zpgRS3H"
      },
      "source": [
        "!unzip WARM_UP.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpWQZXnKLNAU"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "\n",
        "from time import gmtime, strftime\n",
        "\n",
        "def predict(image, predictor, list_labels):\n",
        "    outputs = predictor(image)\n",
        "\n",
        "    boxes = outputs['instances'].pred_boxes\n",
        "    scores = outputs['instances'].scores\n",
        "    classes = outputs['instances'].pred_classes\n",
        "\n",
        "    list_boxes = []\n",
        "    # list_paths = []\n",
        "    # list_vehicles = []\n",
        "    list_scores = []\n",
        "    list_classes = []\n",
        "\n",
        "    for i in range(len(classes)):\n",
        "        if (scores[i] > 0.4):\n",
        "            for j in boxes[i]:\n",
        "                x1 = int(j[0])\n",
        "                y1 = int(j[1])\n",
        "                x2 = int(j[2]) \n",
        "                y2 = int(j[3]) \n",
        "\n",
        "            # print(\"min: \", (x1, y1))\n",
        "            # print(\"max: \", (x2, y2))\n",
        "\n",
        "            score = float(scores[i])\n",
        "            # class_id = list_labels[int(classes[i])]\n",
        "            class_id = classes[i]\n",
        "\n",
        "            list_boxes.append([x1, y1, x2, y2])\n",
        "            list_scores.append(score)\n",
        "            list_classes.append(class_id)\n",
        "\n",
        "    return list_boxes, list_scores, list_classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y86sUqjMLQTZ"
      },
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg as config_detectron\n",
        "\n",
        "# set up detectron\n",
        "path_weigth = \"faster_rcnn_R_101_FPN_3x_model/model_final.pth\"\n",
        "path_config = \"./detectron2/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"\n",
        "confidences_threshold = 0.4\n",
        "num_of_class = 6\n",
        "\n",
        "detectron = config_detectron()\n",
        "detectron.MODEL.DEVICE= 'cuda'\n",
        "detectron.merge_from_file(path_config)\n",
        "detectron.MODEL.WEIGHTS = path_weigth\n",
        "\n",
        "detectron.MODEL.ROI_HEADS.SCORE_THRESH_TEST = confidences_threshold\n",
        "detectron.MODEL.ROI_HEADS.NUM_CLASSES = num_of_class\n",
        "\n",
        "PREDICTOR = DefaultPredictor(detectron)\n",
        "\n",
        "# create labels\n",
        "CLASSES = ['Logo_UIT', 'Logo_HSV', 'Logo_CS', 'Logo_CE', 'Logo_SE', 'Logo_ISE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0pDH-kZMp8L",
        "outputId": "1ce78f0f-b428-4b80-8b4d-65ac91814bc3"
      },
      "source": [
        "path = \"TEST\"\n",
        "list_path_test = glob2.glob(os.path.join(path, \"*.jpg\"))\n",
        "print(len(list_path_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6RMa2mNM5s5",
        "outputId": "eb9e3a61-4749-45e6-d785-ea3d17ab3636"
      },
      "source": [
        "len_list = len(list_path_test)\n",
        "with tqdm(total=len_list) as pbar:\n",
        "  for image_path in list_path_test:\n",
        "    image = cv2.imread(image_path)\n",
        "    image_name = image_path.split(\"/\")[-1]\n",
        "    list_boxes, list_scores, list_classes = predict(image, PREDICTOR, CLASSES)\n",
        "    with open(\"submission.txt\", \"a+\") as f:\n",
        "      for i in range(len(list_boxes)):\n",
        "        class_id = list_classes[i]\n",
        "        bbox = list_boxes[i]\n",
        "\n",
        "        # write submit\n",
        "        f.write(\"{}, {}, {}, {}, {}, {}\\n\".format(image_name, class_id, bbox[0], bbox[1], bbox[2], bbox[3]))\n",
        "    \n",
        "    pbar.update(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 955/955 [02:13<00:00,  7.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}